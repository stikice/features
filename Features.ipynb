{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Features.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPdAH5Z52DvB+Wx9Ojpennu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stikice/features/blob/main/Features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKCdKA51xWRN"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhBzCZjjIf03"
      },
      "source": [
        "import os\n",
        "import csv"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlsW0rTXNZMC"
      },
      "source": [
        "from __future__ import division\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "# Import datasets, classifiers and performance metrics\n",
        "from sklearn import svm\n",
        "#from sklearn.metrics import compare\n",
        "\n",
        "from math import ceil\n",
        "import util\n",
        "from threading import Thread"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bz-2HxiYHYdN"
      },
      "source": [
        "IMG_SIZE = 228\n",
        "Percentage_TESTED = 10\n",
        "#DATA_FILE = 'all_image_features.csv'\n",
        "#DATA_FILE = 'all_image_features_norm.csv'\n",
        "##DATA_FILE = 'top-1-few-features.csv'\n",
        "DATA_FILE = 'all_new_features_hier_norm.csv'\n",
        "PATH_TO_FILES = '/images/val/images'\n",
        "N = 3"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFWWdk4gSPu1"
      },
      "source": [
        "# Nearest Neighbours model - TRAINING and PREDICTION\n",
        "def nearest_neighbour(X_train, X_test, Y_test):\n",
        "    \"\"\"\n",
        "    Nearest neighbour function that returns the prediction of a list of images. With K = 5\n",
        "    Args:\n",
        "        X_train: List of images features used for training\n",
        "        X_test: List of images results used for validate the trained images.\n",
        "        Y_train: List of images features predicted\n",
        "    \"\"\"\n",
        "    # Create and fit a nearest-neighbor classifier\n",
        "    knn = KNeighborsClassifier()\n",
        "    \n",
        "    knn.fit(X_train, X_test)\n",
        "    KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski', metric_params=None, n_jobs=1, n_neighbors=5, p=2, weights='uniform')\n",
        "\n",
        "    # Prediction\n",
        "    predicted = knn.predict(Y_test)\n",
        "\n",
        "    return predicted"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajSDti1f975P"
      },
      "source": [
        "def cv_training_data (amount_images):\n",
        "    \"\"\"\n",
        "    This functions returns the data that will be used for training and test different machine learning models.\n",
        "    This information is collected from the file DATA_FILE.\n",
        "    Return:\n",
        "        data: Data for training the models\n",
        "        data_result: data for validation\n",
        "    \"\"\"\n",
        "\n",
        "    data = []\n",
        "    first_level = []\n",
        "    second_level = []\n",
        "    third_level = []\n",
        "\n",
        "    # Getting the images for training and testing\n",
        "    row_count = 0\n",
        "    with open(DATA_FILE, 'rb') as csvfile:\n",
        "        lines = [line.decode('utf-8-sig') for line in csvfile]\n",
        "\n",
        "        for row in csv.reader(lines):\n",
        "            # Remove the headers of csv file\n",
        "            if row_count is 0:\n",
        "                row_count = row_count + 1\n",
        "                continue\n",
        "\n",
        "            data.append(row[-7:])\n",
        "            first_level.append((row[0],row[1]))\n",
        "            second_level.append((row[0],row[2]))\n",
        "            third_level.append((row[0],row[3]))\n",
        "            row_count = row_count + 1\n",
        "            if row_count > amount_images:\n",
        "                break\n",
        "                \n",
        "    return  data, first_level, second_level, third_level"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rkd3tR6CHqJI",
        "outputId": "d0a7f420-1054-4532-93df-ab0a7c256857",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cv_training_data (N)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([['-0.368491268',\n",
              "   '-0.367459119',\n",
              "   '-0.368733307',\n",
              "   '-0.368210647',\n",
              "   '-0.368290613',\n",
              "   '0.829527447',\n",
              "   '-0.368161599'],\n",
              "  ['-0.367699562',\n",
              "   '-0.367600431',\n",
              "   '-0.368054391',\n",
              "   '-0.368202862',\n",
              "   '-0.36825804',\n",
              "   '1.603893952',\n",
              "   '-0.368161599'],\n",
              "  ['-0.368436687',\n",
              "   '-0.368350366',\n",
              "   '-0.368055402',\n",
              "   '-0.368211152',\n",
              "   '-0.368251844',\n",
              "   '2.728618279',\n",
              "   '-0.368161599']],\n",
              " [('ILSVRC2012_val_00000001.JPEG', '1'),\n",
              "  ('ILSVRC2012_val_00000002.JPEG', '0'),\n",
              "  ('ILSVRC2012_val_00000003.JPEG', '1')],\n",
              " [('ILSVRC2012_val_00000001.JPEG', '1'),\n",
              "  ('ILSVRC2012_val_00000002.JPEG', '0'),\n",
              "  ('ILSVRC2012_val_00000003.JPEG', '1')],\n",
              " [('ILSVRC2012_val_00000001.JPEG', '1'),\n",
              "  ('ILSVRC2012_val_00000002.JPEG', '0'),\n",
              "  ('ILSVRC2012_val_00000003.JPEG', '1')])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2uQjNBYNTYb"
      },
      "source": [
        "def CV_fold_worker(test_idx, train_idx, img_data, first_level, second_level, third_level, first_level_machine, second_level_machine, third_level_machine, return_wrapper):\n",
        "    \"\"\"\n",
        "    Worker function for each fold in CV. Trains a model with training data, tests with\n",
        "    test_idx. Places the results as (image, prediction) tuples in return wrapper\n",
        "    Args:\n",
        "        test_idx: List if indexes where the test_data is\n",
        "        train_idx: List if indexes where the train_data is\n",
        "        img_data: all of the image data\n",
        "        first_level: The names of the classes, respective to model return\n",
        "        return_wrapper: The list to add all results\n",
        "    \"\"\"\n",
        "    # Create a validation set which is 10% of the training_data\n",
        "    X_train, _ = util.list_split(img_data, train_idx, [0])\n",
        "\n",
        "    Y_train, _ = util.list_split(img_data, test_idx, [0])\n",
        "    Y_test_first_level, _ = util.list_split(first_level, test_idx, [0])\n",
        "    Y_test_second_level, _ = util.list_split(second_level, test_idx, [0])\n",
        "    Y_test_third_level, _ = util.list_split(third_level, test_idx, [0])\n",
        "\n",
        "    X_test_first_level, _ = util.list_split(first_level, train_idx, [0])\n",
        "    X_test_second_level, _ = util.list_split(second_level, train_idx, [0])\n",
        "    X_test_third_level, _ = util.list_split(third_level, train_idx, [0])\n",
        "\n",
        "    X_val_first_level = [X_test_first_level[i][1] for i in range(0,len(X_test_first_level))]\n",
        "    Y_val_first_level = [Y_test_first_level[i][1] for i in range(0,len(Y_test_first_level))]\n",
        "\n",
        "    X_val_second_level = [X_test_second_level[i][1] for i in range(0,len(X_test_second_level))]\n",
        "    Y_val_second_level = [Y_test_second_level[i][1] for i in range(0,len(Y_test_second_level))]\n",
        "\n",
        "    X_val_third_level = [X_test_third_level[i][1] for i in range(0,len(X_test_third_level))]\n",
        "    Y_val_third_level = [Y_test_third_level[i][1] for i in range(0,len(Y_test_third_level))]\n",
        "\n",
        "    list_predictions = []\n",
        "    Y_train_second_level = []\n",
        "    Y_train_second_level_position = []\n",
        "    Y_train_third_level = []\n",
        "    Y_train_third_level_position = []\n",
        "\n",
        "    ##################################################################################################################\n",
        "    # First Level of hierarchy [Mobilnet_v1]\n",
        "    ##################################################################################################################\n",
        "    if first_level_machine == 'nn':\n",
        "        predicted = nearest_neighbour(X_train, X_val_first_level, Y_train)\n",
        "        \n",
        "    for position, prediction in enumerate(predicted):\n",
        "            if prediction == '1':\n",
        "                if Y_test_first_level[position][1] == '1':\n",
        "                    list_predictions.append((Y_test_first_level[position][0], 1, prediction, 1, 'tf-mobilenet_v1'))\n",
        "                else:\n",
        "                    list_predictions.append((Y_test_first_level[position][0], 0, prediction, 1, 'tf-mobilenet_v1'))\n",
        "            else:\n",
        "                Y_train_second_level.append(Y_train[position])\n",
        "                Y_train_second_level_position.append(position)\n",
        "\n",
        "    # Not necessary to go to the next level\n",
        "    if len(Y_train_second_level) == 0:\n",
        "        return_wrapper.append(list_predictions)\n",
        "        return\n",
        "\n",
        "    ##################################################################################################################\n",
        "    # Second Level of hierarchy [Inception_v4]\n",
        "    ##################################################################################################################\n",
        "    #predicted = nearest_neighbour(X_train, X_val_second_level, Y_train_second_level)\n",
        "    #predicted_level_2, predicted_level_5, predicted_level_8, predicted_level_12, predicted_level_16 = decision_tree(X_train, X_val, Y_train)\n",
        "    #predicted = predicted_level_16\n",
        "    #predicted = vecto_classifier(X_train, X_val, Y_train)\n",
        "\n",
        "    if second_level_machine == 'nn':\n",
        "        predicted = nearest_neighbour(X_train, X_val_second_level, Y_train_second_level)\n",
        "\n",
        "    for position, prediction in enumerate(predicted):\n",
        "            if prediction == '1':\n",
        "                if Y_test_second_level[position][1] == '1':\n",
        "                    list_predictions.append((Y_test_first_level[Y_train_second_level_position[position]][0], 2, prediction, 2, 'tf-inception_v4'))\n",
        "                else:\n",
        "                    list_predictions.append((Y_test_first_level[Y_train_second_level_position[position]][0], 0, prediction, 2, 'tf-inception_v4'))\n",
        "            else:\n",
        "                Y_train_third_level.append(Y_train_second_level[position])\n",
        "                Y_train_third_level_position.append(Y_train_second_level_position[position])\n",
        "\n",
        "    if len(Y_train_third_level) == 0:\n",
        "        return_wrapper.append(list_predictions)\n",
        "        return\n",
        "\n",
        "    ##################################################################################################################\n",
        "    # Third Level of hierarchy [Resnet_v1_152]\n",
        "    ##################################################################################################################\n",
        "    #predicted = nearest_neighbour(X_train, X_val_third_level, Y_train_third_level)\n",
        "    #predicted_level_2, predicted_level_5, predicted_level_8, predicted_level_12, predicted_level_16 = decision_tree(X_train, X_val_third_level, Y_train_third_level)\n",
        "    #predicted = predicted_level_16\n",
        "    #predicted = vecto_classifier(X_train, X_val, Y_train)\n",
        "\n",
        "    if third_level_machine == 'nn':\n",
        "        predicted = nearest_neighbour(X_train, X_val_third_level, Y_train_third_level)\n",
        "        \n",
        "    for position, prediction in enumerate(predicted):\n",
        "            if prediction == '1':\n",
        "                if Y_test_third_level[position][1] == '1':\n",
        "                    list_predictions.append((Y_test_first_level[Y_train_third_level_position[position]][0], 3, prediction, 3, 'tf-resnet_v1_152'))\n",
        "                else:\n",
        "                    list_predictions.append((Y_test_first_level[Y_train_third_level_position[position]][0], 0, prediction, 3, 'tf-resnet_v1_152'))\n",
        "            else:\n",
        "                if Y_test_third_level[position][1] == '1':\n",
        "                    list_predictions.append((Y_test_first_level[Y_train_third_level_position[position]][0], 3, prediction, 0, 'failed'))\n",
        "                else:\n",
        "                    list_predictions.append((Y_test_first_level[Y_train_third_level_position[position]][0], 0, prediction, 0, 'failed'))\n",
        "\n",
        "\n",
        "    return_wrapper.append(list_predictions)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_AkcoqeTZtU"
      },
      "source": [
        "def prototype(amount_images, list_premodels):\n",
        "    \"\"\"\n",
        "    Produce a .csv file with the fields <Image_filename, Ground truth model, predicted model>\n",
        "    for every image in the train information set. We use k-fold cross validation, where k=10.\n",
        "    \"\"\"\n",
        "    percetange_results = []\n",
        "\n",
        "    if len(list_premodels) == 0:\n",
        "        print(\"No premodels were selected!\")\n",
        "        return percetange_results\n",
        "    if amount_images == 0:\n",
        "        print(\"No images were selected!\")\n",
        "        return percetange_results\n",
        "    \n",
        "    #print(\"Creating training data...\")\n",
        "    data, first_level_data, second_level_data, third_level_data = cv_training_data(amount_images)\n",
        "    for counter,(first_level_machine, second_level_machine, third_level_machine) in enumerate(list_premodels):\n",
        "        # Split training data in k-fold chunks\n",
        "        # Minimum needs to be 2\n",
        "        k_fold = 2\n",
        "        worker_threads = list()\n",
        "        chunk_size = int(ceil(len(data) / float(k_fold)))\n",
        "\n",
        "        # Create a new thread for each fold\n",
        "        print(range(len(data))[0])\n",
        "        for i, (test_idx, train_idx) in enumerate(util.chunkise(range(len(data)), chunk_size)):\n",
        "            return_wrapper = list()\n",
        "            p = Thread(target=CV_fold_worker, args=(test_idx, train_idx, data, first_level_data, second_level_data, third_level_data, first_level_machine, second_level_machine, third_level_machine, return_wrapper))\n",
        "            p.start()\n",
        "            worker_threads.append((p, return_wrapper))\n",
        "\n",
        "        # Wait for threads to finish, collect results\n",
        "        all_predictions = list()\n",
        "        for p, ret_val in worker_threads:\n",
        "            p.join()\n",
        "            all_predictions += ret_val\n",
        "\n",
        "        predicted = []\n",
        "        correct_result = []\n",
        "\n",
        "        for p in all_predictions:\n",
        "            for image, groundtruth_label, result_prediction, prediction, model_predicted in p:\n",
        "                correct_result.append(groundtruth_label)\n",
        "                predicted.append(prediction)\n",
        " \n",
        "        percetange_results.append(compare.calculate_percentage(predicted, correct_result, [list_premodels[counter]]))\n",
        "    \n",
        "    return percetange_results"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anWkLqP6Uc3p",
        "outputId": "f9b95083-078d-4554-c579-33b4f644784b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "list_premodels_selected = [('nn', 'nn', 'nn')]\n",
        "prototype(N, list_premodels_selected)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-812f657ef3e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlist_premodels_selected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprototype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_premodels_selected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-26-51474ddb01f3>\u001b[0m in \u001b[0;36mprototype\u001b[0;34m(amount_images, list_premodels)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Create a new thread for each fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunkise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mreturn_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mThread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCV_fold_worker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_level_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond_level_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthird_level_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_level_machine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond_level_machine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthird_level_machine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/util.py\u001b[0m in \u001b[0;36mchunkise\u001b[0;34m(l, n)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \"\"\"\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         yield l[i:i+n)], l[:i] + l[i+n:]\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'range' and 'range'"
          ]
        }
      ]
    }
  ]
}